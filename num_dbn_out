digraph {
	graph [size="18.45,18.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140290648342832 [label="
 (128, 256)" fillcolor=darkolivegreen1]
	140290648220240 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	140290648220768 -> 140290648220240
	140290648220768 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (128, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (256, 1)"]
	140290648220480 -> 140290648220768
	140290768354496 [label="
 (256)" fillcolor=lightblue]
	140290768354496 -> 140290648220480
	140290648220480 [label=AccumulateGrad]
	140290648219952 -> 140290648220768
	140290648219952 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	140290648220720 -> 140290648219952
	140290648220720 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (128, 512)
mat1_strides:       (512, 1)
mat2        : [saved tensor]
mat2_sizes  :     (512, 256)
mat2_strides:       (256, 1)"]
	140290648220864 -> 140290648220720
	140290768360608 [label="
 (256)" fillcolor=lightblue]
	140290768360608 -> 140290648220864
	140290648220864 [label=AccumulateGrad]
	140290648220816 -> 140290648220720
	140290648220816 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (128, 25)
mat1_strides:        (25, 1)
mat2        : [saved tensor]
mat2_sizes  :      (25, 512)
mat2_strides:        (1, 25)"]
	140290648220960 -> 140290648220816
	140290764675728 [label="
 (512)" fillcolor=lightblue]
	140290764675728 -> 140290648220960
	140290648220960 [label=AccumulateGrad]
	140290648221008 -> 140290648220816
	140290648221008 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140290648221152 -> 140290648221008
	140290648221152 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140290648221344 -> 140290648221152
	140290648221344 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	140290648221440 -> 140290648221344
	140290648221440 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (128, 25)
mat1_strides:        (25, 1)
mat2        : [saved tensor]
mat2_sizes  :       (25, 25)
mat2_strides:        (1, 25)"]
	140290648221632 -> 140290648221440
	140290764699344 [label="
 (25)" fillcolor=lightblue]
	140290764699344 -> 140290648221632
	140290648221632 [label=AccumulateGrad]
	140290648221584 -> 140290648221440
	140290648221584 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140290648221728 -> 140290648221584
	140290648221728 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140290648221920 -> 140290648221728
	140290648221920 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	140290648222016 -> 140290648221920
	140290648222016 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (128, 25)
mat1_strides:        (25, 1)
mat2        : [saved tensor]
mat2_sizes  :       (25, 25)
mat2_strides:        (1, 25)"]
	140290648222208 -> 140290648222016
	140290764699504 [label="
 (25)" fillcolor=lightblue]
	140290764699504 -> 140290648222208
	140290648222208 [label=AccumulateGrad]
	140290648222160 -> 140290648222016
	140290648222160 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140290648222304 -> 140290648222160
	140290648222304 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140290648222496 -> 140290648222304
	140290648222496 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	140290648222592 -> 140290648222496
	140290648222592 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (128, 25)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (25, 25)
mat2_strides:        (1, 25)"]
	140290648222784 -> 140290648222592
	140290770807040 [label="
 (25)" fillcolor=lightblue]
	140290770807040 -> 140290648222784
	140290648222784 [label=AccumulateGrad]
	140290648222736 -> 140290648222592
	140290648222736 [label=TBackward0]
	140290648222832 -> 140290648222736
	140290770808480 [label="
 (25, 25)" fillcolor=lightblue]
	140290770808480 -> 140290648222832
	140290648222832 [label=AccumulateGrad]
	140290648222544 -> 140290648222496
	140290770771536 [label="
 (25)" fillcolor=lightblue]
	140290770771536 -> 140290648222544
	140290648222544 [label=AccumulateGrad]
	140290648222400 -> 140290648222496
	140290770771136 [label="
 (25)" fillcolor=lightblue]
	140290770771136 -> 140290648222400
	140290648222400 [label=AccumulateGrad]
	140290648222112 -> 140290648222016
	140290648222112 [label=TBackward0]
	140290648222640 -> 140290648222112
	140290764699584 [label="
 (25, 25)" fillcolor=lightblue]
	140290764699584 -> 140290648222640
	140290648222640 [label=AccumulateGrad]
	140290648221968 -> 140290648221920
	140290770939152 [label="
 (25)" fillcolor=lightblue]
	140290770939152 -> 140290648221968
	140290648221968 [label=AccumulateGrad]
	140290648221824 -> 140290648221920
	140290770939232 [label="
 (25)" fillcolor=lightblue]
	140290770939232 -> 140290648221824
	140290648221824 [label=AccumulateGrad]
	140290648221536 -> 140290648221440
	140290648221536 [label=TBackward0]
	140290648222064 -> 140290648221536
	140290764699424 [label="
 (25, 25)" fillcolor=lightblue]
	140290764699424 -> 140290648222064
	140290648222064 [label=AccumulateGrad]
	140290648221392 -> 140290648221344
	140290770797888 [label="
 (25)" fillcolor=lightblue]
	140290770797888 -> 140290648221392
	140290648221392 [label=AccumulateGrad]
	140290648221248 -> 140290648221344
	140290770797808 [label="
 (25)" fillcolor=lightblue]
	140290770797808 -> 140290648221248
	140290648221248 [label=AccumulateGrad]
	140290648221056 -> 140290648220816
	140290648221056 [label=TBackward0]
	140290648221488 -> 140290648221056
	140290243387040 [label="
 (512, 25)" fillcolor=lightblue]
	140290243387040 -> 140290648221488
	140290648221488 [label=AccumulateGrad]
	140290648220576 -> 140290648220720
	140290648220576 [label=TBackward0]
	140290648221872 -> 140290648220576
	140290648221872 [label=TBackward0]
	140290648221200 -> 140290648221872
	140290768360848 [label="
 (512, 256)" fillcolor=lightblue]
	140290768360848 -> 140290648221200
	140290648221200 [label=AccumulateGrad]
	140290648220432 -> 140290648220768
	140290648220432 [label=TBackward0]
	140290648221296 -> 140290648220432
	140290648221296 [label=TBackward0]
	140290648222256 -> 140290648221296
	140290768354656 [label="
 (256, 256)" fillcolor=lightblue]
	140290768354656 -> 140290648222256
	140290648222256 [label=AccumulateGrad]
	140290648220240 -> 140290648342832
}
