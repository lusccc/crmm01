{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-01T22:02:13.203089Z",
     "end_time": "2023-04-01T22:02:29.763984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de05c30beca844dfae6574c09e0cef9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import generic wrappers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "# Define the model repo\n",
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "\n",
    "\n",
    "# Download pytorch model\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Transform input tokens\n",
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "\n",
    "# Model apply\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "===========================================================================\nLayer (type:depth-idx)                             Param #\n===========================================================================\nBertModel                                          --\n├─BertEmbeddings: 1-1                              --\n│    └─Embedding: 2-1                              3,906,816\n│    └─Embedding: 2-2                              65,536\n│    └─Embedding: 2-3                              256\n│    └─LayerNorm: 2-4                              256\n│    └─Dropout: 2-5                                --\n├─BertEncoder: 1-2                                 --\n│    └─ModuleList: 2-6                             --\n│    │    └─BertLayer: 3-1                         198,272\n│    │    └─BertLayer: 3-2                         198,272\n├─BertPooler: 1-3                                  --\n│    └─Linear: 2-7                                 16,512\n│    └─Tanh: 2-8                                   --\n===========================================================================\nTotal params: 4,385,920\nTrainable params: 4,385,920\nNon-trainable params: 0\n==========================================================================="
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T22:02:29.766179Z",
     "end_time": "2023-04-01T22:02:29.792030Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n    (position_embeddings): Embedding(512, 128)\n    (token_type_embeddings): Embedding(2, 128)\n    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-1): 2 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=128, out_features=128, bias=True)\n            (key): Linear(in_features=128, out_features=128, bias=True)\n            (value): Linear(in_features=128, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=128, out_features=128, bias=True)\n            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=128, out_features=512, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=512, out_features=128, bias=True)\n          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=128, out_features=128, bias=True)\n    (activation): Tanh()\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-01T22:04:54.985855Z",
     "end_time": "2023-04-01T22:04:55.043567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
